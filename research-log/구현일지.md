# 전체 정리
- Term-based scoring
- LSH Regularization
  - Query token embedding과 Document LSH간 비교 속도는 빠르고 성능은 term간 비교와 거의 유사
  - centroid 정의, 최근접 클러스터 구할 때, 샘플링 시 활용
- Incremental Clustering
  - K-means initialization and streaming clustering
  - 초기 최적화하기보다 continual context에서 다른 방법 대비 성능 향상 보여주기

---

# 1차 피드백 정리
- 클러스터 warming up process
  - 초기화 좋은 걸로 시작하게 SS기준 BisectingKMeans 적용
  - LSH 시 SS를 term간 비교로 해서 자동 k detect될 거 같음
- negative sample 정의
  - 클러스터 최소 2개 필요
  - 1개일 때 정의불가: 하지만 예외사항임 고려X
- LSH 적용 히스토리
  - term 기반인데 mean embedding기반 거리 비교
  - 고정길이 프로토타입 생성
    - 클러스터 할당 및 최적 k 결정에 사용

# 샘플링은 최초 임베딩 기준으로 하는데, model update는 새로 임베딩해서 하는게 맞냐 기존 임베딩으로 하는 게 맞냐
- 부차적문제) 기존 임베딩 불러와서 쓰면 트래킹이 됨?
- 샘플링 때 기존 임베딩끼리 샘플링하고, 업데이트할 때 샘플들 새로 임베딩해서 하면 현재 표현 기준으로 업데이트됨


# 대용량 전처리
- HDFS 파일락킹 필요한데 NFS같은 file system은 다중 클라이언트 지원때매 이런거 지원 안함
- 로컬 디렉토리에 작업 후 옮겨야함
  - 시스템에 영향을 주지 않으면서 사용할 수 있는 기본 비휘발성 디렉터리
  - 사용자 홈 디렉터리
  - /usr/local: 사용자 정의 애플리케이션이나 라이브러리 파일을 저장
  - /opt: 서드파티 소프트웨어나 애플리케이션을 설치하기 위한 디렉터리
  - /var: 시스템의 가변 데이터를 저장하는 데 사용됩니다. 로그 파일이나 데이터베이스 파일 등
- 권한 문제
  - ! mkdir -p ~/my_data
  - ~ 기호는 쉘에서 현재 사용자의 홈 디렉터리를 나타내지만, Python 코드에서 사용할 때는 이 기호가 해석되지 않음
    -  os.path.expanduser 함수를 사용하여 홈 디렉터리를 올바르게 해석해야 함 ㅅㅂ


# 클러스터 응집도 지표 
- 내부 거리(internal distance)  
  - 클러스터 내의 모든 샘플 간의 평균 거리로, 낮은 값일수록 응집도가 높음을 나타냅니다.
- Silhouette Score (실루엣 계수)
  - 개별 샘플의 군집 내 응집도와 다른 군집 간의 분리를 평가합니다.
  - 값은 -1에서 1까지이며, 1에 가까울수록 클러스터의 응집도가 높습니다.
- Davies-Bouldin Index (DB 지수)
  - 클러스터 간의 거리와 클러스터 내의 평균 거리의 비율로, 값이 낮을수록 클러스터 간의 분리가 좋고 응집도가 높습니다.
- Dunn Index
  - 클러스터 내의 거리와 클러스터 간의 거리 비율을 나타냅니다.
  - 값이 높을수록 응집도가 높고 분리가 잘 이루어져 있다는 것을 의미합니다.
- Within-Cluster Sum of Squares (WCSS):
  - 각 클러스터의 중심에서 각 샘플까지의 거리 제곱합으로, 낮은 값이 클러스터의 응집도를 높게 나타냅니다.
- Calinski-Harabasz Index
  - 클러스터 내의 분산과 클러스터 간의 분산 비율을 나타내며, 값이 높을수록 응집도가 좋습니다.
 
---

# 배치 사이즈가 성능향상에 기여하는 이유
- 배치당 샘플 다양성 반영, 노이즈 감소(정규화 효과)
- 모델이 작거나 학습이 불안정할 때

# mean pooling
- padding이 있는 경우, padding을 제외한 토큰의 mean pooling을 위해 attention mask를 활용합니다.

# BERT 학습 시에는 어떻게 임베딩? 
- cls? mean pooling? 간단한 mlp(pooler layer?)
- [CLS]분류 작업을 위한 "집계 표현"으로 작용하지만, 이것이 고품질 문장 임베딩 벡터에 대한 최상의 선택은 아니라는 점에 유의해야 합니다 .
- 다른 토큰들의 self-attention에 의한 weighted sum. 모든 입력의 첫 번째 토큰, 대응하는 의미가 없어 집계쵸현이 됨

# long context embedding
- 문서 청킹
  - 똥같은 bert tokenizer는 토크나이징된 리스트로는 가변길이 문자열 처리를 못 함
  - 다시 재결합해서 string으로 넣어주거나, padding+truncate 동시 적용해서 같은 토큰 시퀀스 되게 하거나....
  - is_split_into_words는 이미 단어단위 되어있는가 여부
- overlap으로 문맥정보 넣되, 중복 처리 않도록 함
- [CLS]와 [SEP] 제외
  - last_hidden_state[batch/문장 수, 토큰 수, 768]
 
---
# 시간 병목 지점은 꼭 확인 하자..
- 쓸데없이 계산(클러스터링)
- extend(not list)같이 동작하는데 비정상인 부분..

# 평가 지표
- Success@k: 상위 k개의 결과에 정답이 하나라도 포함되어 있는지 여부를 측정 (정확성 측정).
- Recall@k: 상위 k개의 결과에 정답 문서들이 얼마나 많이 포함되어 있는지 비율을 측정 (포괄성 측정).


# 약간 성능 변화
- 리스트에서 텐서로 변환할 때나 배치 처리 방식에서 정밀도 차이가 발생할 수 있으며, 이러한 차이는 작은 계산 오차로 이어질 수 있습니다.
- 두 번째 코드가 텐서 연산에 최적화되어 있기 때문에 더 일관되고 정확한 결과를 제공할 가능성이 큽니다.

--- 

# Kmeans++
- K 결정
  - SSE 감소율이 급격하게 줄어드는 k
    - SSE (Sum of Squared Errors): 각 데이터 포인트와 해당 클러스터 중심과의 차이의 제곱합
  - 실루엣 점수가 가장 높은 k 
- centroid 초기화
  - 데이터 포인트 중 하나 랜덤 선택
  - 나머지 데이터 포인트가 centroid 후보가 된다
    - 그 데이터 포인트가 centroid로 뽑힐 확률
      - P(x_i) = D(x_i)^2 / sum(D(x_i)^2)
      - D(x_i) : 가장 가까운 centroid까지의 거리
  - k개 뽑힐 때까지 반복한다 
- 할당/중심 갱신
  - 최대 반복 횟수 지정
  - 중심점 이동량 제한
 
# 클러스터링에서의 RMS와 분산의 차이점
- RMS(클러스터의 크기)
  - RMS는 각 데이터 포인트의 크기에만 집중합니다. 따라서 각 데이터의 제곱이 커질수록 RMS 값이 커지며, 데이터의 절대적인 크기를 반영합니다.
  - 클러스터링에서는 클러스터의 크기나 중심과의 거리를 고려할 때 유용하지 않을 수 있습니다.
- 분산(클러스터의 응집도)
  - 분산은 데이터 포인트들이 중심에서 얼마나 퍼져 있는지를 보여줍니다.
  - 클러스터링에서 클러스터의 응집도를 평가하는 데 유용하며, 클러스터 내의 데이터가 얼마나 밀집되어 있는지 또는 퍼져 있는지 이해하는 데 중요한 지표입니다.
- 요약
  - RMS는 모든 데이터 포인트의 제곱합의 평균을 나타내므로, 분산을 계산하는 데 필요한 각 데이터 포인트와 평균 사이의 거리와도 연결될 수 있습니다.
  - 다만, RMS는 **평균에서의 차이 뿐 아니라 데이터 값의 절대적인 크기도 반영하**는 반면, 분산은 **데이터 포인트들이 평균에서 얼마나 벗어나 있는지**를 강조합니다.
 

# 평가지표도 샘플링 비율에 맞춰야한다..!
---
# 얼만큼의 문서를 남기는가, 프로토타입은 학습에 사용되는 가상샘플인가? 오로지 클러스터 관리 목적인가?
- 극단적으로 문서를 남기지 않거나, 모두 남기거나 할 수 있음
  - 프로토타입만 유지하는 경우에는 샘플로도 사용할 수 있을 것
- 데이터셋마다 조정 비율 달라질 것임

# L2R
1. 매번 새로 임베딩하고 있나? 
  - 모델 호환성이 없으면 이전 세션 문서들 새로 임베딩, 아니면 재사용
2. eval set도 도메인 변화 모사하나? 
  - 맞음(세션 나눈 후 분할)
  - D0에는 labeled positive, D1~3에는 unlabeled/labeled positive 섞여있음 
  - lebeled positve가 주어지고, negative sampling 수행해서 인코더 업데이트 하는 것은 동일
  - 위음성 강건성
3. 쿼리와 쿼리버퍼 언제 탈락?
  - 언급X
---

# 실험 셋팅
- 세션 별 도메인 비율에 맞는 평가/테스트 셋

# 1개짜리 클러스터로 인한 문제 휴리스틱
- positive의 경우, 자기자신 사용
- negative의 경우, 모자란 만큼 다음 negative cluster의 것 사용

# 세션 별 학습량이 다른데(D0쿼리량이 D123의 3배 정도) 동일한 epochs?
- ..
  
# centroid 업데이트 필요?
- 새 세션의 데이터 할당 후 한 번에?인스턴스 들어올 때마다?
- 업데이트 시점에 기억해둔 통계량들이 쓸모 없어짐. 
- 현 상태 기준 centroid/통계량 갱신 -> 갱신 centroid, 통계량 기반 eviction -> 새로운 데이터할당(통계유효성위해 중심벡터 고정) -> 추가된 할당 정보 기반 샘플링 및 학습 ....


---
# BCELoss vs. BCEWithLogitsLoss
- 모델 마지막 Layer가 Sigmoid 혹은 Softmax로 되어 있는 경우(모델 출력이 확률 값인 경우)
- 모델 출력이 Logits(확률 변환 전 실수 값)인 경우
