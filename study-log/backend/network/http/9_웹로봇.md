# 웹로봇
- 사람과의 상호작용 없이 연속된 웹 트랜잭션들을 자동으로 수행하는 프로그램
- 크롤러, 스파이더, 웜, 봇

# 크롤러와 크롤링
- 페이지와 그 페이지가 가리키는 페이지를 재귀적으로 가져오는 박업
- 검색엔진 스파이더
- 루트집합(URL)에서 시작
- 순환피하기(루트와 중복 제거)
  - 트리와 해시테이블
  - URL을 고정크기 해싱하고, 배열 내 presense bit에 매핑
  - 디스크에 체크포인팅 되어있는가
  - 파티셔닝(일부 집합만 할당)
  - 동일 URL 다른 Alias, URL 정규화
  - 파일 시스템 심볼릭 링크 BFS
  - 스로틀링, 일정시간동안 가져올 수 있는 페이지 제한
  - URL최대길이제한(DFS)
