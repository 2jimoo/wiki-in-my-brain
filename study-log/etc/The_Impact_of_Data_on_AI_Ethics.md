# Meterials
https://www.miricanvas.com/v/130fo3v

# Content
1_발표의 목적

기업이 사용하는 모델의 공개만큼 기업이 사용하는 데이터가 공개되고 있는가
- GIGO, 아무리 AI 모델의 판단 과정이 투명하더라도 데이터에 문제가 있으면 최종 의사결정에 문제가 발생할 수 밖에 없습니다.
- 따라서 AI 모델과 모델의 설명력 뿐 아니라 기업에서 어떤 데이터를 사용하고 있는지도 중요할 것입니다.
- 이렇게 기업에서 사용하는 데이터를 공개하면 사용한 데이터의 저작권, 사용 데이터 공개를 위해 개인정보를 어떻게 마스킹할 것인가 등의 논의까지 이어질 수 있겠습니다.
- 공개의무와 관련된 법률 예시와 오픈 데이터가 오픈 소스만큼 활성화 되기 위해 어떤 기준과 고민들이 필요할지 살펴보겠습니다.


데이터의 생성과정은 환경에 어떤 영향을 미치는가 
- 데이터를 저장하는 데이터센터와 관련된 환경적 이슈에는 익숙하실 겁니다,
- 그러나 데이터를 생성 및 가공, 증각하는 과정에서도 인공지능이 사용이 됩니다.
- 두 과정에서 발생하는 문제들, 법률과 기술적 대안들을 대략적으로 알아보고자 합니다,

고품질 데이터의 부족으로 인해 발생하는 AI ethics 문제들 
- 많은 AI의 학습데이터들이 웹으로부터 발생합니다. 
- 그러나 모델의 발전 속도를 데이터가 따라가지 못 한다는 연구들이 있습니다, 이에 따라 AI가 생성해내는 가비지 데이터들이 인간이 생성해낸 데이터들보다 많아지는 것 아닌지 
또 그런 가비지 데이터의 비율이 높아져 AI의 학습에 다시 영향을 끼치지는 않을지 고민해볼 수 있을 것 같습니다,
- AI가 사용하는 데이터 퀄리티가 AI bias에 어떻게 영향을 주는지 알아보고, 고품질 데이터를 생성하기 위한 인간의 역할을 알아보려고 합니다, 


2_불투명성-감사 표준 정의
-Grok, devika, llama 등 기업의 AI 모델들이 오픈소스로 공개되어있습니다. 
좋은 의도도 있겠지만 개인이나 소규모 기업들이 이런 모델을 자기들만큼 훈련시킬 데이터와 컴퓨팅 자원이 없을 거라는 계산일 것 같습니다. 
아무튼 이렇게 공개된 모델들이 100% 설명력을 가진다고 해도 기업이 사용하는 데이터를 알 수 없으면 반쪽짜리 설명력일 것 입니다. 

AI Foundation Model Transparency Act
- 기초 모델 데이터 소스 및 학습 투명성에 대해 기업이 공개해야할 정보 명시
- 계산 능력에 대한 정보
- 훈련 데이터의 출처
- 저작권에 위반되는지 
  - https://www.theverge.com/2023/12/22/24012757/ai-foundation-model-transparency-act-bill-copyright-regulation 
- 개인정보 보호를 고려하면서 광범위한 인구통계 정보, 언어 정보 및 기타 속성 정보를 포함하는 훈련 데이터의 크기 및 구성에 대한 설명
- 위험 수준이 더 높은 상황에 대답하거나 대응하기 위해 기초 모델이 취하는 예방 조치는 무엇을 해놓았는지
- 업계 표준 벤치마크에서 자체적으로 또는 감사 
  - 감사 표준화를 위해 Fact-checking / Bias-checking benchmark dataset이 오픈데이터로, 다양한 도메인에 대해 제공이 되어야함

 Data quality and artificial intelligence – mitigating bias and error to protect fundamental rights(European Union Agency for Fundamental Rights)
- 대표성과 측정 오류가 낮은 고품질 데이터가 없다면, 대량의 데이터는 측정의 타당성을 증가시키지 않습니다.
- 예측의 정확성 vs 인구 그룹에 대한 일반 통계
- 저품질 데이터로 학습 시 미치는 영향 
  - 측정력 저하 사례 ex) 법정 시스템- 공정한 재판과 효과적인 구제권, 좋은 행정의 원칙에 부정적인 영향. 
  - 대표성 오류는 데이터가 잘 커버되지 않는다 ex) 특정 인종이 많은 데이터로 학습시... 또는 새로운 정보에 대응 못 함
- 인증된 소스 및 무형 데이터를 사용하는 품질 및 보안의 원칙
- 인터넷 사용하지 않는 그룹을 대표하지 못 한다. EU-28에서 인터넷을 사용하여 소셜 네트워크에 참여하는 개인은 약 절반 가량(56%)입니다.

- 비차별성 권리(EU 기본권헌장 제21조)
- 남녀 평등(기본권헌장 제23조)
- 공정한 재판 및 효과적인 구제권(기본권헌장 제47조)
- 개인 및 가족 생활의 존중 (기본권헌장 제7조) 및 개인 데이터 보호 (기본권헌장 제8조)
- 선량한 행정의 원칙
- 해당 데이터에 대해 알고, 액세스하고, 정정하고, 삭제하고, 이에 이의를 제기할 수 있는 권리(GDPR)

데이터의 품질을 평가할 때 많은 기준을 고려할 수 있습니다. 
 일반적으로 데이터 품질은 완전성, 정확성, 일관성, 시기 적절성, 중복, 유효성, 가용성 및 출처 등 다양한 문제를 포함합니다.
FRA의 대규모 EU 이민 데이터베이스에서 생체 인식 데이터 사용에 대한 연구는 데이터의 품질, 특히 영숫자 데이터와 생체 인식 식별자의 정확성이 개인 데이터 보호에 부정적인 영향을 미칠 수 있음을 강조했습니다.
 EU의 대규모 데이터베이스인 비자 정보 시스템(VIS)이나 쉥겐 정보 시스템(SIS II)과 같은 시스템에서 개인에 대한 잘못된 데이터가 상당히 흔하게 보고됩니다.
새로운 기술과 대규모 데이터베이스에 대한 신뢰는 종종 사람들이 데이터가 부정확할 수 있다는 사실을 잊게 만듭니다.

데이터 양은 측정이나 예측의 정확성에 대한 기준 중 하나일 뿐입니다. 
실제 세계를 얼마나 잘 나타낼 수 있는지, 데이터에 기반한 통계적 정확성을 해결하려면 데이터 품질과 함께 평가되어야 합니다. 

'데이터 품질'의 한 정의는 사용된 데이터가 "목적에 적합한"지 여부입니다
책임감과 투명성이라는 데이터 보호 원칙에서 직접 파생됩니다. 그러나 저작권, 지적 재산권 및 비즈니스 비밀과 같은 문제에 대한 투명성은 어려울 수 있습니다.
데이터가 실시간으로 수집 및 분석/반영 되지 않는다 

하드웨어 구성 요소가 산업 표준을 준수하는지 확인하기 위해 설명되는 방식과 유사하게 데이터셋을 설명하는 것이 제안됩니다. 사람들에 대한 정보를 포함하는 데이터셋은 데이터셋 생성, 구성, 데이터 수집 프로세스, 사전 처리 및 데이터셋 분포에 대한 자세한 정보를 포함하여 유사하게 설명될 수 있습니다. 현재 AI 분야에서 합의된 표준화된 데이터셋 설명 방식은 없습니다. 이러한 표준화는 AI 애플리케이션에서 사용되는 다양한 가능한 데이터 형식과 컬렉션을 포함할 수 있는 유연성을 허용해야 합니다. 이는 데이터가 하나의 목적으로 생성된 경우 다른 목적에도 적합한지 평가해야 하기 때문에 중요합니다.
예를 들어, 데이터 문서화 이니셔티브(DDI)는 사회, 행동, 경제 및 건강 과학 분야의 설문 조사 및 기타 데이터 소스로부터의 데이터 설명을 위한 국제 표준 

데이터 품질을 평가할 수 있으려면 데이터 수집의 맥락뿐만 아니라 방법론, 데이터 및 메타 데이터 수준의 설명이 필요합니다. 이에는 데이터를 얻기 위해 사용된 방법론에 대한 정보, 데이터에 포함된 인구 및 관찰 단위에 대한 정보, 데이터 수집 방법(예: 인터뷰, 온라인 추적 등), 표본 추출 절차, 시간 및 지리적 범위에 대한 정보가 포함됩니다. 이 정보를 통해 애플리케이션 사용자는 특정 데이터 세트를 사용하는 도구의 품질과 잠재적 오류를 더 잘 평가할 수 있습니다. 

 데이터는 어디에서 왔나요? 데이터 수집, 유지 및 배포에 대한 책임은 누구에게 있나요?  데이터에는 어떤 정보가 포함되어 있나요? 알고리즘의 목적에 적합한 정보가 데이터에 포함되어 있나요?  데이터에는 누가 포함되어 있나요? 데이터에서 누가 대표되지 않나요?  데이터 세트 내에 정보가 누락되어 있거나 일부 단위만 부분적으로 커버되어 있나요?  애플리케이션 구축에 사용된 데이터 수집의 시간적 및 지리적 범위는 어떻게 되나요?

비용이 많이 드는 데이터 획득에 투자하는 것은 비용 절감에 기여하지 않을 수 있으므로, 쉽게 이용 가능한 데이터 소스가 종종 선호됩니다
인터넷은 합의된 소스가 아니다(계획되어 생산된 데이터가 아니다)


3_고갈/양극화-공유

 데이터 고갈 - AI chatbots could hit a ceiling after 2026 as training data runs dry
- 작년에 발표된 논문에서 연구진은 현재의 AI 훈련 추세가 계속된다면 2026년 이전에 고품질 텍스트 데이터가 고갈될 것이라고 예측했습니다. 
- 저품질 언어 데이터는 2030년에서 2050년 사이에, 저품질 이미지 데이터는 2030년에서 2060년 사이에 고갈될 것으로 추정했습니다.
- ...비전 데이터가 2030년에서 2070년 사이에 소진될 것으로 보인다.
- Self-supervised Learning, Synthetic data... 유망한 방법이지만 실제 세상 반영도 떨어질 수 있고, 과적합 위험

한계점 
- 동등한 수준의 성능을 달성하기 위해 미래에는 데이터가 덜 필요할 수 있습니다.
- 컴퓨팅 자원의 가용성이 예상보다 느리게 성장할 수 있습니다. 
- 현재의 스케일링 법칙이 잘못되었을 수 있습니다
- 멀티모달 모델이 전이 학습을 통해 단일 모달리티 모델보다 더 나은 성능을 발휘할 수도 있다
- 합성 데이터, 정부 등의 개입, 저품질데이터로부터 고품질을 만들게 될 수도 있다...

- 우리는 고품질 데이터셋이 보통 50%의 스크랩된 사용자 생성 콘텐츠(Pile-CC, OpenWebText2, 소셜 미디어 대화, 필터링된 웹페이지, MassiveWeb, C4), 
15-20%의 책,  10-20%의 과학 논문, <10%의 코드, 그리고 <10%의 뉴스로 구성된다는 것을 알 수 있습니다. 
또한, 이들은 모두 위키피디아와 같은 알려진 소량의 매우 고품질 데이터셋을 포함합니다(그림 4a).

- 저품질 언어와 비전 재고의 고갈 날짜에 상당한 불확실성이 있지만, 2030년 이전이나 2060년 이후에 발생할 가능성은 낮아 보입니다. 
그러나 현재 추세가 계속된다면 고품질 언어 재고는 거의 확실히 2027년 이전에 고갈될 것입니다.
- 지난 4년 동안 언어 모델의 성능 향상 중 절반 정도는 더 많은 데이터로 훈련함으로써 이루어졌습니다. (22년기준)데이터셋을 더 이상 확장할 여지가 없다면, 이는 AI 진보의 둔화로 이어질 것입니다.

Tools and Weapons(Smith, Brad , Browne, Carol Ann , Gates, Bill), Open data initiative
제가 좋아하는 책입니다, 
MS의 변호사 브래드 스미스가 독점금지법, 클라우드 호환성과 인권문제로 CloudAct를 제정한 이야기를 하고 있습니다.
기술에 대해 적절한 규제는 필요하며, 정부의 역할을 강조하지만 기업도 적극적으로 먼저 위험사항을 제시하고 참여해야한다고 얘기합니다. 
빠른 시장선점의 신화 속에서 기업들이 얼마나 고민이 많을지는 알겠지만, 사회적인 팩임을 다하더라도 여전히 충분히 성공할 수 있다고 말합니다.

AI와 데이터에 대해서도 의견이 나오는데 간단히 살펴보겠습니다.

오픈 데이터까지의 합의
- 기관들은 데이터를 공유할것인가?
- 어떻게 공유하고 어떤 조건을 달것인가?

오픈 데이터의 조건
- 프라이버시 보호
 - 비식별형 프라이버시(ditterential privacy)기술
 - 인정보가 포함된 데이터에서 개인정보의 일부 또는 전부를 삭제하거나 대체함으로써 다른 정보와 쉽게 결합해도 특정인을 식별하기 어렵도록 하는 조치
 -
- 보안
 - 복수개 기관의 접근
- 데이터 소유권, 통제권의 공유
 - 여러 집단이 어떻게 사용할 것인가, 공유하는 조건은 무엇인가
 - 오픈소스와 비슷하게 진행될 것이다.
 - 정부가 주도하여 소기관의 데이터 부족현상을 줄여주자.(오바마, 트럼프 행저부 모두 정부기관들에게 이와 같은 내용 요구했었음)
- 지적 재산권/저작권
- 적은 비용으로 더 쉽게 데이터를 공유할 수 있는 기술 플랫폼 필요

그러나 이 내용도 AI가 나오기 이전 제정된 내용이므로 갱신이 필요하다는 애기를 합니다. 
인간의 대표성과 환경을 위해 


4_환경 오염-에너지 정책, 기술

AI를 서비스하는 것 뿐아니라 데이터 관점에서도, 데이터 보관과 Raw data 가공등에 사용되는 AI가 사용되며 엄청난 전기 소모 발생(데이터센터)

Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives 
 ICT가 환경에 미치는 직접적인 영향을 자주 측정하는 방법은 ICT 운영에 사용되는 에너지입니다. 기술 성능 및 효율성 향상으로 인해 전반적인 운영 에너지 효율성이 감소하여 다른 제품(예: 자동차, 건물)에 비해 훨씬 낮습니다. 그러나 ICT 제조 과정에서 사용되는 에너지는 다른 제품에 비해 훨씬 높으며, ICT 제품의 전체 수명주기를 평가할 필요성이 주목받고 있다(Williams 2011 ).  
또한 전력 부족 시 서버 작동을 유지하기 위해 디젤 발전기를 가동해야 하는데, 이로 인해 기후 변화에 결과적으로 영향을 미치는 온실 가스가 배출됩니다...
추정에 따르면, 클라우드 컴퓨팅의 발전과 인터넷 서비스 사용의 증가로 인해 데이터 센터는 모니터링이 필요한 전체 ICT 부문에서 탄소 배출량이 가장 빠르게 증가하고 있습니다

데이터센터의 에너지 소비와 온실가스 배출은 ICT가 직접적으로 미치는 영향 중 하나일 뿐이다. 
1) 컴퓨팅 하드웨어를 폐기하면 유해한 방출이 발생하므로 더 많은 주의가 필요합니다.
2) 환경 영향을 평가하려면 사용자의 행동 및 관행과 관련된 ICT의 간접적인 영향을 고려해야 합니다
  - jevons paradox vs rebound effect
  - 기술의 성능이 높아져 효율성이 높아지고 에너지 소비와 가격이 낮아지더라도 소비자는 전반적인 환경 영향이 증가하면서 ICT에 더 많은 돈을 지출할 수 있습니다.
  - 간접 영향은 평가에 더 큰 행동적, 사회적 측면을 고려해야 하기 때문에 평가하기가 매우 어렵습니다.

1) 데이터 저장의 물질적 차원과 환경적 요인을 직접 느껴야한다. 모호한 표현X 조사O
- 데이터가 제한된 자원이라는 점을 인정할 수 있게 하며, 물리적 환경에서 지속 가능하고 책임감 있는 행동을 안내하는 일부 규범과 원칙이 디지털 환경의 맥락에서도 적용되어야 함을 제안합니다.

Energy policies and regulations

- 양자 컴퓨팅
  - IBM, 구글, 마이크로소프트, 아마존웹서비스, 후지쯔 등 
- 저전력 AI 반도체 
  -, 최소한의 데이터가 필요하도록 모델을 개선한다.
- AI 역사를 살펴보면 태초에 Symbolic AI가 있었고, 이후 인간의 뉴런과 블랙박스 동작을 모델링해 DNN 모델들로 이어졌죠,
최근에는 인간의 지각과 인지능력을 본따 이 두 모델을 융합한 Neuro-Symbolic모델 컨셉이 떠오르고 있습니다, 
그렇게 방대하지 않은 데이터, 온전히 정의된 규칙에 의해 동작하기 떄문에 신뢰도와 설명력 
- 짐켈러 “GPU는 AI에 적합한 칩은 아니다" '추론 전용' 하드웨어
- 핵융합발전 
  - OpenAI(hellion)
- 소형모듈원전(SMR) 
  - MS, OpenAI, Google 공장옆에 지어야지 히히 하는 중
  - 사용 후 핵연료 처리 기술 이슈 
  - 전력망 구축 이슈



5_개인은 어떻게 해야하나

“지구력있게” 생각하는 연습을 해야한다고 생각합니다.
정치와 환경에 대한 관심
  - IT에 대한 이해도가 높은 정치인, IT에 관련된 요구를 많이 하는 시민. 정책은 꾸준히 갱신되어야함(책에서도 강조된 내용)
  -  IT종사자는 자신들만 기술을 이해하고 있다는 오만에서 벗어나야한다... 소통해라
  -  국가간의 합의도 중요하다(기술이 한 나라의 정부보다 규모가 크다)
  - 엔지니어와 기업의 국가편향성
     -중국과 미국의 인력 흡수 문제

진위와 소스에 대한 경각심 
세상에 존재하지 않는 Factual한 데이터를 만드는 것이 당분간의 인간의 역할이 되지 않을까 싶습니다.
이 데이터의 근원과 수집 방법 등에 대해 의심해야한다…
입모양도 맞춰주고, 음성 15초면 다 하는디… 

창의성의 재정의
단순 다른 개념의 조합과 분해는 이미 AI로도 달성가능한 수준의 창의성이라고 생각합니다.
우리는 앞으로 이러한 답이 없는 문제를 발굴하고 지속적으로 검토하고 논의하여 시대에 맞게 갱신하는 것이 새로운 창의성이 될지 모른다.


6_정리
데이터 관점에서 인공지능 윤리와 관련된 이슈들을 살펴보았습니다.
데이터 불투명성 - 감사 표준, 데이터의 메타정보 표준 정의, 공개 의무화, 고품질데이터의 인권적 중요성
고갈, 불균형성 - 오픈 데이터의 필요성과 조건, 사례
환경 오염 - 직간접적 영향, 국가와 기업의 노력
위 이슈들을 살펴본 결과 개인이 할 수 있는 일은 생각 지구력을 키우는 것
정치와 환경에 대한 관심
진위와 소스에 대한 경각심
습관이 되기전까진 피곤할 것 같긴하다. 우리네 화이팅!
