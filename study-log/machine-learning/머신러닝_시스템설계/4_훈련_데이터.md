# 훈련 데이터
- 훈련/검증/테스트 포함
- 이슈
  - 다중성
  - 레이블 부족
  - 클래스 불균형
  - 데이터 부족(증강)
  - 잠재적 편향

 
# 샘플링
- 목적
  - 가용한 전체 실데이터에서 훈련셋 생성하기 위해
  - 훈련/검증/테스트 분할
  - 모니터링
- 비확률 샘플링
  - 확률에 기반하지 않는 방법, 편리하고 선택 편향이 강함, 프로젝트 초기
  - 언어 모델링, 감성분석, 자율주행 자동차훈련 등
  - 편의 샘플링(가용성), 눈덩이 샘플링(기존 샘플 기반 미래 샘플 선택), 판단 샘플링(전문가), 할당 샘플링(임의 그룹별)
- 확률 기반 샘플링
  - 무작위 샘플링
    - 드물게 발생하는 데이터는 포함 안 될 가능성 높음
  - 계층적 샘플링
    - 모집단을 그룹핑하여 각 그룹에서 K%씩 샘플링
    - 항상 가능하지만은 않음(특히 다중레이블 - 여러 그룹에 속할 수 있을 때)
  - 가중 샘플링
    - 각 샘플에 도메인 지식기반 가중치가 있음
    - 샘플 가중치: 선택될 확률X 학습 시 손실함수에 반영강도
  - 저수지 샘플링
    - 스트리밍 데이터
  - 중요도 샘플링
    - 원하는 확률분포가 아닌 다른 확률분포만 이용가능할 때
    - 정책기반 강화학습 등 새로운 정책이 이전 정책과 유사할 때.

   
# 레이블링
- 수작업 레이블
  - 레이블 다중성: 소스별 지식 수준 상이한 어노테이터에 의해 결과 불일치
  - 데이터 계보: 샘플과 레이블의 출처 트래킹
- 자연 레이블
  - 추천시스템, 자연적인 그라운드 트루스 레이블 
  - 명시적/암시적 피드백 받기
  - 피드백 루프길이: 속도와 정확도의 트레이드 오프
- 레이블 부족
  - 약한 지도 학습
    - 휴리스틱으로 레이블 생성
    - 스노클,  Labeling function(키워드, 정규표현식, 데이터베이스, 다른 모델의 출력)
  - 준지도 학습
    - 레이블 생성 논리를 구성하기 위해 약간 레이블 필요, 그 이후 X
    - self-training: 특징-레이블 학습, 교란기반
  - 전이 학습
    - 훈련데이터가 많고 수집 비용이 저렴한 작업 후 미세조정 
  - 능동적 학습
    - 모델이 레이블이 필요하다고 판단한 샘플을 어노테이터에게 요청
    - 불확실성(손실 or 모델간 합치)이 가장 높은 데이터 포인트 선택, 결정경계 잘 학습
   

# 클래스 불균형
- ML 모델 성능에 매우 큰 영향(실제 패턴 학습X)
- 접근법
  - 지표 선정
    - 정밀도, 재현율, F1은 비대칭 지표 - 어떤 클래스를 양성으로 간주할 것인가
    - ROC-AUC
  - 데이터 분포 변경
    - 리샘플링(오버샘플링, 언더샘플링)
      - 실제 데이터분포가 아니므로 여기서 평가X
    - 토멕링크(언더샘플링)
      - 소수 클래스 샘플에 근접한 다수 클래스 샘플 제거
      - 결정경계는 명확해지나, 정확한 경계 캡쳐 못 함
    - SMOTE(오버샘플링)
      - 고차원 데이터에서 비용 크거나 불가
    - 동적 샘플링
    - 2단계 학습  
  - 학습 방법론 변경
    - 비용 민감 학습
    - 클래스 균형 손실 ex. Focal loss
   
# 데이터 증강
- 단순 레이블 보존 변환
  - 레이블 유지하고 이미지 무작위 수정
- 교란
- 데이터 합성 
  
