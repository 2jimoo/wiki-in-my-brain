# 모델 개발과 훈련
- 학습 곡선으로 데이터가 늘어남에 따라 모델성능이 미래에 어떻게 변할지
- 성능지표간 트레이드오프
- 모델 별 가정 이해(어느 유스케이스에 적합할 것인가 결정하기 위해)
  - Prediction assumption
    - 입력 X에서 출력 Y를 예측하는 것이 목표인 모델은 X를 기반으로 Y를 예측할 수 있다
  - Independent and Identically Distributed
    - 신경망은 각각의 데이터 포인트가 독립적이고 분포가 동일하다고 가정
  - Smoothness
    - 유사한 입력은 유사한 출력을 갖는다 
  - Tractability
    - 계산가능성, X는 입력이고 Z는 X의 잠재표현이라고 할 때 생성모델은 확률 P(X|Z)를 계산할 수 있다 
  - Boundaries
    - 선형분류기는 결정경계가 선형이라고 가정함
  - Conditional Independence
    - 나이브 베이즈 분류기는 정해진 클래스에 대해 속성값들이 상호독립이라고 가정함
  - Normally distributed
    - 데이터가 정규분포를 따른다고 가정
- 앙상블
  - 기본 학습기들의 다수결 투표
  - 배깅
    -  분산을 즐이고 과적합 방지에 효과적
    -  복원추출해서 부트스크랩 구성 후 각 부트스크랩으로 기본 학습기 훈련
    -  불안정성 성능 개선 ex. random forest
  - 부스팅
    - 이전 약한 학습기의 오차를 집중훈련해서 강한 훈련기로 만든다
  - 스태킹
    - 기본학습기들의 출력을 결합해 최종예측 수행하는 메타학습기를 만든다
   
# 실험 추적과 버전관리
- 재현에 필요한 모든 정의 추적 필요
  - 손실곡선, 평가 손실 그래프, 로그, 매개변수, 하이퍼 파라미터, 시스템 성능 지표 등
- 모델 뿐 아니라 데이터의 버저닝

# 분산 훈련
- 배치 병렬 처리
  - 그래디언트 체크 포인팅
  - 파이프라이닝
- 오토ML
  - 하이퍼 파라미터 최적화
  - 아키텍쳐 탐색(NAS)
 
# 오프라인평가
- 베이스라인
- 노이즈 강건성, 불변성 테스트, 예상한 방향으로 변하는가, 슬라이스 기반 평가
