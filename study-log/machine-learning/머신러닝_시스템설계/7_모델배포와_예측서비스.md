# 배포
- 모델을 실행하고 액세스 가능하게 함
- 모델 직렬화
- 온라인 예측(동기), 배치 예측(비동기)
- 디바이스 상 배포, 클라우드 상 배포

# 배치 예측/온라인 예측
- 예측 유형
  - 배치 피처만 사용하는 배치 예측
  - 배치 피처만 사용하는 온라인 예측
  - 배치 피처와 스트리밍 피처를 모두 사용하는 온라인 예측(스트리밍 예측)
    - ex. 지난 10분간의 통계
- 파이프라인 통합
  - 2개 파이프라인 관리하면 버그만 많지
  - 스트리밍 엔진, 피처 스토어
 
# 모델 압축
- 저차원 인수분해
  - 고차원 텐서를 저차원 텐서로 대체
  - 소형 합성곱 필터 등 특정 모델 한정 기법 
- 지식 증류
- 가지치기
- 양자화
  - 반올림 오차로 성능 변화 가능
  - 양자화 고려한 훈련/사후훈련 필요
 
# 디바이스 별 실행
- 특정 하드웨어 백엔드에서 컴파일 및 최적화 필요
  - CPU 스칼라 / GPU 벡터 / TPU 텐서 단위로 연산 
- 중간표현(IR)
  - 고수준 IR
    - ML모델의 계산그래프, 계산 순서 설명
  - 튜닝된 IR
  - 저수준 IR
  - 기계코드
- 모델 최적화 in 컴파일러
  - 로컬 최적화
    - 모델 연산자 집합 최적화, 작업 병렬화, 칩 액세스 최소화
    - 벡터화(인접 메모리 동시 실행해 IO줄임), 병렬화(텐서 나눠 독립적 처리), 루프 타일링(루프에서 액세스 순서 바꿔 캐시 등 활용), 연산자 융합
  - 글로벌 최적화
    - End-to-End 경로 최적화 ex. cuDNN, autoTVM
    - 계산 그래프를 부분으로 나눔, 각 부분 그래프의 크기 예측/최상의 경로 검색 시간 할당, 각 부분 그래프 실행해 전체 그래프 최적 경로 도출
- 브라우저 웹 어셈블리  
